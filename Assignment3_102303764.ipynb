{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN6tGhtH2b+Ycsm21R3XPjk"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X8JmqEgD9RIZ"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1 - Step a: Load USA House Price Dataset and Split Features/Target\n"
      ],
      "metadata": {
        "id": "gKyl-B8VET7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "url_house = \"https://drive.google.com/uc?id=1O_NwpJT-8xGfU_-3llUl2sgPu0xllOrX\"\n",
        "house_data = pd.read_csv(url_house)\n",
        "\n",
        "# Input features (all except Price)\n",
        "X = house_data.drop('Price', axis=1).values\n",
        "y = house_data['Price'].values.reshape(-1,1)\n",
        "\n",
        "print(\"Input shape:\", X.shape)\n",
        "print(\"Output shape:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6jnk8hGBoof",
        "outputId": "0b5a87eb-24e3-4ea4-9b38-bff16ab7af0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (5000, 5)\n",
            "Output shape: (5000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1 - Step b: Scale Input Features\n"
      ],
      "metadata": {
        "id": "g0brUEabEZUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "8jlp0eRWCKVc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1 - Step c & d: 5-Fold Cross Validation using Least Squares Fit\n"
      ],
      "metadata": {
        "id": "5uAVifWLEdgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "r2_scores = []\n",
        "beta_list = []\n",
        "\n",
        "for i, (train_index, test_index) in enumerate(kf.split(X_scaled)):\n",
        "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    # Add bias term\n",
        "    X_train_bias = np.hstack((np.ones((X_train.shape[0],1)), X_train))\n",
        "    X_test_bias = np.hstack((np.ones((X_test.shape[0],1)), X_test))\n",
        "\n",
        "    # Least Squares: β = (X^T X)^(-1) X^T y\n",
        "    beta = np.linalg.inv(X_train_bias.T @ X_train_bias) @ (X_train_bias.T @ y_train)\n",
        "\n",
        "    # Predict\n",
        "    y_pred = X_test_bias @ beta\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    r2_scores.append(r2)\n",
        "    beta_list.append(beta)\n",
        "\n",
        "    print(f\"Fold {i+1}: R² score = {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81rZmy2GCmKo",
        "outputId": "4d09881c-d53a-4141-eb8b-425b6061b715"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: R² score = 0.9180\n",
            "Fold 2: R² score = 0.9146\n",
            "Fold 3: R² score = 0.9116\n",
            "Fold 4: R² score = 0.9193\n",
            "Fold 5: R² score = 0.9244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1 - Step e: Select Best Beta and Train on Full Dataset\n"
      ],
      "metadata": {
        "id": "ysNHXNbFEhcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_index = np.argmax(r2_scores)\n",
        "best_beta = beta_list[best_index]\n",
        "print(f\"Best R2_score (Fold): {r2_scores[best_index]:.4f}\")\n",
        "\n",
        "# Train on full dataset using best beta\n",
        "X_bias_full = np.hstack((np.ones((X_scaled.shape[0],1)), X_scaled))\n",
        "y_pred_full = X_bias_full @ best_beta\n",
        "final_r2 = r2_score(y, y_pred_full)\n",
        "print(f\"R2 score on full dataset: {final_r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvsyw3XuCvdH",
        "outputId": "3d31d03f-a593-4955-b79d-152356235e3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best R2_score (Fold): 0.9244\n",
            "R2 score on full dataset: 0.9180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2 - Step 1: Split Dataset into Training (56%), Validation (14%), Test (30%)\n"
      ],
      "metadata": {
        "id": "OwlUvqqKEkRX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split train_temp (70%) and test (30%)\n",
        "X_train_temp, X_test, y_train_temp, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Split train_temp into train (56%) and validation (14%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_temp, y_train_temp, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train set:\", X_train.shape)\n",
        "print(\"Validation set:\", X_val.shape)\n",
        "print(\"Test set:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcpaSDH9DED1",
        "outputId": "04b95e1d-0a4b-4b0a-9af5-3f3bf805fd28"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set: (2800, 5)\n",
            "Validation set: (700, 5)\n",
            "Test set: (1500, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2 - Step 2: Define Gradient Descent Function\n"
      ],
      "metadata": {
        "id": "QMKvrScfEmfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X, y, lr=0.01, iterations=1000):\n",
        "    m, n = X.shape\n",
        "    beta = np.zeros((n,1))\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        y_pred = X @ beta\n",
        "        gradient = (1/m) * (X.T @ (y_pred - y))\n",
        "        beta -= lr * gradient\n",
        "\n",
        "    return beta"
      ],
      "metadata": {
        "id": "JHbmV7ZvDdek"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2 - Step 3: Add Bias Term to Input Features\n"
      ],
      "metadata": {
        "id": "-tgj03W_EoYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_bias = np.hstack((np.ones((X_train.shape[0],1)), X_train))\n",
        "X_val_bias = np.hstack((np.ones((X_val.shape[0],1)), X_val))\n",
        "X_test_bias = np.hstack((np.ones((X_test.shape[0],1)), X_test))"
      ],
      "metadata": {
        "id": "xOiThvUlDkmf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2 - Step 4: Train Using Gradient Descent for Different Learning Rates\n"
      ],
      "metadata": {
        "id": "DYQDuYDCEp-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.001, 0.01, 0.1, 1]\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    beta = gradient_descent(X_train_bias, y_train, lr=lr, iterations=1000)\n",
        "\n",
        "    y_val_pred = X_val_bias @ beta\n",
        "    y_test_pred = X_test_bias @ beta\n",
        "\n",
        "    r2_val = r2_score(y_val, y_val_pred)\n",
        "    r2_test = r2_score(y_test, y_test_pred)\n",
        "\n",
        "    results.append({'learning_rate': lr, 'beta': beta, 'R2_val': r2_val, 'R2_test': r2_test})\n",
        "\n",
        "    print(f\"Learning rate: {lr}, R² val: {r2_val:.4f}, R² test: {r2_test:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41mevc_WDnNu",
        "outputId": "2a1e5966-13ab-4fdb-b131-76c2124c495d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate: 0.001, R² val: -0.8125, R² test: -0.9914\n",
            "Learning rate: 0.01, R² val: 0.9098, R² test: 0.9147\n",
            "Learning rate: 0.1, R² val: 0.9098, R² test: 0.9148\n",
            "Learning rate: 1, R² val: 0.9098, R² test: 0.9148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2 - Step 5: Find Best Learning Rate Based on Validation Set\n"
      ],
      "metadata": {
        "id": "SpLW3qvcEslQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_result = max(results, key=lambda x: x['R2_val'])\n",
        "print(\"Best learning rate:\", best_result['learning_rate'])\n",
        "print(\"Validation R²:\", best_result['R2_val'])\n",
        "print(\"Test R²:\", best_result['R2_test'])\n",
        "print(\"Regression coefficients (β):\\n\", best_result['beta'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUPlbvLJDrRP",
        "outputId": "9d1b14e1-ac6d-402a-ff3a-6ec7bdfb0083"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best learning rate: 0.01\n",
            "Validation R²: 0.9098183094422969\n",
            "Test R²: 0.9147434800538763\n",
            "Regression coefficients (β):\n",
            " [[1232562.51254919]\n",
            " [ 230048.76664688]\n",
            " [ 163686.93503606]\n",
            " [ 121406.94107918]\n",
            " [   3117.47363933]\n",
            " [ 150655.97459714]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3 - Step 1 & 2: Load Dataset and Handle Missing Values\n"
      ],
      "metadata": {
        "id": "A-ldjoo0FRDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Column names\n",
        "columns_car = [\"symboling\", \"normalized_losses\", \"make\", \"fuel_type\", \"aspiration\",\n",
        "               \"num_doors\", \"body_style\", \"drive_wheels\", \"engine_location\", \"wheel_base\",\n",
        "               \"length\", \"width\", \"height\", \"curb_weight\", \"engine_type\", \"num_cylinders\",\n",
        "               \"engine_size\", \"fuel_system\", \"bore\", \"stroke\", \"compression_ratio\",\n",
        "               \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "# Load dataset\n",
        "url_car = \"https://archive.ics.uci.edu/ml/machine-learning-databases/autos/imports-85.data\"\n",
        "car_data = pd.read_csv(url_car, names=columns_car, na_values='?')\n",
        "\n",
        "# Convert numeric columns to float\n",
        "numeric_cols_car = [\"symboling\", \"normalized_losses\", \"wheel_base\", \"length\", \"width\", \"height\",\n",
        "                    \"curb_weight\", \"engine_size\", \"bore\", \"stroke\", \"compression_ratio\",\n",
        "                    \"horsepower\", \"peak_rpm\", \"city_mpg\", \"highway_mpg\", \"price\"]\n",
        "\n",
        "for col in numeric_cols_car:\n",
        "    car_data[col] = pd.to_numeric(car_data[col], errors='coerce')\n",
        "\n",
        "# Impute missing numeric values\n",
        "car_data[numeric_cols_car] = car_data[numeric_cols_car].fillna(car_data[numeric_cols_car].mean())\n",
        "\n",
        "# Drop rows with NaN price\n",
        "car_data = car_data.dropna(subset=['price'])\n",
        "car_data['price'] = car_data['price'].astype(float)"
      ],
      "metadata": {
        "id": "snObOchwFQtq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3 - Step 3: Convert Non-Numeric Columns to Numeric\n"
      ],
      "metadata": {
        "id": "jDkdPIhtFVMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# num_doors and num_cylinders\n",
        "word_to_num = {\"two\":2, \"three\":3, \"four\":4, \"five\":5, \"six\":6, \"eight\":8, \"twelve\":12}\n",
        "car_data['num_doors'] = car_data['num_doors'].map(word_to_num)\n",
        "car_data['num_cylinders'] = car_data['num_cylinders'].map(word_to_num)\n",
        "\n",
        "# Dummy encoding for body_style and drive_wheels\n",
        "car_data = pd.get_dummies(car_data, columns=['body_style', 'drive_wheels'], drop_first=True)\n",
        "\n",
        "# Label encoding for make, aspiration, engine_location, fuel_type\n",
        "label_cols = ['make', 'aspiration', 'engine_location', 'fuel_type']\n",
        "le = LabelEncoder()\n",
        "for col in label_cols:\n",
        "    car_data[col] = le.fit_transform(car_data[col])\n",
        "\n",
        "# Fuel system: pfi -> 1, else 0\n",
        "car_data['fuel_system'] = car_data['fuel_system'].apply(lambda x: 1 if 'pfi' in str(x).lower() else 0)\n",
        "\n",
        "# Engine type: ohc -> 1, else 0\n",
        "car_data['engine_type'] = car_data['engine_type'].apply(lambda x: 1 if 'ohc' in str(x).lower() else 0)"
      ],
      "metadata": {
        "id": "kpM1yV1KFV_v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3 - Step 4: Divide into Input Features (X) and Output (y) and Scale Features\n"
      ],
      "metadata": {
        "id": "NKX8YZ5PFYSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Input features and target\n",
        "X_car = car_data.drop('price', axis=1).values\n",
        "y_car = car_data['price'].values.reshape(-1,1)\n",
        "\n",
        "# Scale features\n",
        "X_car_scaled = scaler.fit_transform(X_car)  # reuse the scaler from Q1/Q2"
      ],
      "metadata": {
        "id": "wY76oRjfFZpx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3 - Step 5: Train Linear Regression and Test Performance\n"
      ],
      "metadata": {
        "id": "KDC5Fl6eFcDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure all numeric columns in car_data\n",
        "numeric_cols_car = car_data.drop('price', axis=1).columns\n",
        "\n",
        "for col in numeric_cols_car:\n",
        "    car_data[col] = pd.to_numeric(car_data[col], errors='coerce')\n",
        "\n",
        "# Drop any rows with NaN (safest)\n",
        "car_data = car_data.dropna(subset=numeric_cols_car)\n",
        "\n",
        "# Now separate X and y\n",
        "X_car = car_data.drop('price', axis=1).values\n",
        "y_car = car_data['price'].values.reshape(-1,1)\n",
        "\n",
        "# Scale features\n",
        "X_car_scaled = scaler.fit_transform(X_car)\n",
        "\n",
        "X_train_car, X_test_car, y_train_car, y_test_car = train_test_split(\n",
        "    X_car_scaled, y_car, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "lr_car = LinearRegression()\n",
        "lr_car.fit(X_train_car, y_train_car)\n",
        "\n",
        "y_pred_car = lr_car.predict(X_test_car)\n",
        "r2_car = r2_score(y_test_car, y_pred_car)\n",
        "print(\"Linear Regression R² on test set:\", r2_car)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NixcE7YrFeDf",
        "outputId": "6d442e43-a1fa-4b62-dfca-eb59c8a794b2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression R² on test set: 0.7718101387808747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3 - Step 6: PCA Dimensionality Reduction and Train Linear Regression\n"
      ],
      "metadata": {
        "id": "M9nFczGvFftX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply PCA to retain 95% variance\n",
        "pca = PCA(n_components=0.95)\n",
        "X_train_pca = pca.fit_transform(X_train_car)\n",
        "X_test_pca = pca.transform(X_test_car)\n",
        "\n",
        "# Train Linear Regression on PCA features\n",
        "lr_pca = LinearRegression()\n",
        "lr_pca.fit(X_train_pca, y_train_car)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_pca = lr_pca.predict(X_test_pca)\n",
        "r2_pca = r2_score(y_test_car, y_pred_pca)\n",
        "print(\"Linear Regression R² on test set after PCA:\", r2_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M9ueznJFhFp",
        "outputId": "2729b6c2-dd5b-403b-908b-6484e928a1ac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression R² on test set after PCA: 0.7296545680543669\n"
          ]
        }
      ]
    }
  ]
}